{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "import requests\n",
    "import contextlib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.imdb.com/search/title?release_date=2015-01-01,2016-03-31&runtime=60,&title_type=feature&user_rating=5.0,10\n",
      "Movies:   3164\n",
      "Write In: 3164\n",
      "Duration: 00:02:37\n"
     ]
    }
   ],
   "source": [
    "### 存取設定範圍內之電影連結\n",
    "\n",
    "# Release Date\n",
    "r_date_min = '2015-01-01'\n",
    "r_date_max = '2016-03-31'\n",
    "\n",
    "# User Rating\n",
    "u_rating_min = 5.0 \n",
    "u_rating_max = 10 \n",
    "\n",
    "# Runtime\n",
    "rt = 60\n",
    "\n",
    "# Title Type\n",
    "movie_feature = 'feature'\n",
    "\n",
    "url = 'http://www.imdb.com/search/title?release_date='+r_date_min+','+r_date_max+'&runtime='+str(rt)+',&title_type='+movie_feature +'&user_rating='+str(u_rating_min)+','+str(u_rating_max)\n",
    "res = requests.get(url, verify=True)\n",
    "sp = BeautifulSoup(res.text)\n",
    "print url\n",
    "\n",
    "total = ''.join(sp.find('div', {'id':'left'}).text.split('of')[1].split('\\n')[0].split(','))\n",
    "print 'Movies:  ' + str(total)\n",
    "\n",
    "k=0\n",
    "tStart = time.time()\n",
    "\n",
    "with open('data/IMDB/movies_link.txt', 'w') as f1:\n",
    "    \n",
    "    for i in range(0,(int(total)/50)+1):\n",
    "        \n",
    "        try:\n",
    "            each_url = url + '&start=' +str(i*50+1)\n",
    "            #print each_url\n",
    "            \n",
    "            res = requests.get(each_url, verify=True)\n",
    "            res.encoding = 'utf-8'\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            title = soup.findAll('td', {'class':'title'})\n",
    "            \n",
    "            for a in title:\n",
    "                f1.write('http://www.imdb.com' + a.find('a')['href'])\n",
    "                f1.write('\\n')\n",
    "                \n",
    "        except BaseException, e:\n",
    "            print e\n",
    "\n",
    "with open('data/IMDB/movies_link.txt', 'r') as f2: \n",
    "\n",
    "    for j in f2.readlines():\n",
    "        k=k+1\n",
    "        \n",
    "print 'Write In: ' + str(k)\n",
    "print 'Duration: ' + time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - tStart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', error(10054, '\\xbb\\xb7\\xba\\xdd\\xa5D\\xbe\\xf7\\xa4w\\xb1j\\xa8\\xee\\xc3\\xf6\\xb3\\xac\\xa4@\\xad\\xd3\\xb2{\\xa6s\\xaa\\xba\\xb3s\\xbdu\\xa1C'))\n",
      "http://www.imdb.com/title/tt4428720/\n",
      "Movies: 3163\n",
      "Duration: 02:19:19\n"
     ]
    }
   ],
   "source": [
    "with contextlib.nested(open('data/IMDB/movies_link.txt', 'r'),\n",
    "                       open('data/IMDB/movies_detail.txt', 'w'),\n",
    "                       open('data/IMDB/movies_director.txt', 'w'),\n",
    "                       open('data/IMDB/movies_writer.txt', 'w'),\n",
    "                       open('data/IMDB/movies_actor.txt', 'w'),\n",
    "                       open('data/IMDB/movies_miss.txt', 'w')) as (f0,f1,f2,f3,f4,f5): \n",
    "\n",
    "    tStart = time.time()\n",
    "    \n",
    "    for url in f0.readlines():\n",
    "        \n",
    "        try:\n",
    "            res0 = requests.get(url.strip(), verify=True)\n",
    "            res0.encoding = 'utf-8'\n",
    "            sp0 = BeautifulSoup(res0.text)\n",
    "\n",
    "            # IMDB movie sno\n",
    "            sno =  url.split('title/')[1].replace('/', '').strip()\n",
    "\n",
    "            # IMDB movie title\n",
    "            #movie_title = sp0.find('span', {'class':'itemprop'}).text\n",
    "            #movie_title = sp0.find('div', {'id':'ratingWidget'}).find('strong').text\n",
    "            try:\n",
    "                movie_title = sp0.find('div', {'id':'ratingWidget'}).find('strong').text.strip()\n",
    "            except AttributeError, ae:\n",
    "                movie_title = re.sub(r'(\\(\\))', '', re.sub(r'(\\d)', '', sp0.find('h1', {'itemprop':'name'}).text.strip()))\n",
    "  \n",
    "            # IMDB movie duration\n",
    "            movie_duration = sp0.find('time', {'itemprop':'duration'})['datetime'].replace('PT','').replace('M','')\n",
    "            \n",
    "            # IMDB movie genre\n",
    "            genre = []\n",
    "            movie_story = sp0.find('div', {'id':'titleStoryLine'})\n",
    "            item = movie_story.find('div', {'itemprop':'genre'})   \n",
    "            try:\n",
    "                for g in item.findAll('a'):\n",
    "                    genre.append(g.text.strip())\n",
    "                    \n",
    "            except BaseException, e:\n",
    "                genre.append('None')\n",
    "                \n",
    "            movie_genre = ','.join(genre)\n",
    "            \n",
    "            # IMDB movie datePublished\n",
    "            movie_date = sp0.find('meta', {'itemprop':'datePublished'})['content']\n",
    "\n",
    "            # IMDB movie rate value\n",
    "            try:\n",
    "                movie_rate_value = sp0.find('span', {'itemprop':'ratingValue'}).text\n",
    "            except BaseException, e:\n",
    "                movie_rate_value = ''\n",
    "                \n",
    "            # 123,456 IMDb users have given a weighted average vote of 9.5/10\n",
    "            try:\n",
    "                movie_rate_count = sp0.find('span', {'itemprop':'ratingCount'}).text.replace(',', '')\n",
    "            except BaseException, e:\n",
    "                movie_rate_count = ''\n",
    "            \n",
    "            # Write in detail.txt\n",
    "            f1.write(sno + \";\" + movie_title.encode('utf-8') + \";\" + movie_duration.encode('utf-8') + \";\" + movie_genre.encode('utf-8') + \";\" + movie_date.encode('utf-8') + \";\" + movie_rate_value.encode('utf-8') + \";\" + movie_rate_count.encode('utf-8'))\n",
    "            f1.write('\\n')\n",
    "\n",
    "            movie_fullcredits_url = url.strip() + 'fullcredits'\n",
    "            res1 = requests.get(movie_fullcredits_url, verify=True)\n",
    "            res1.encoding = 'utf-8'\n",
    "            sp1 = BeautifulSoup(res1.text)\n",
    "\n",
    "            # IMDB movie director/writer\n",
    "            fullcredits = sp1.select(\"#fullcredits_content\")[0]\n",
    "            h4_class =  fullcredits.findAll('h4', {'class':'dataHeaderWithBorder'})\n",
    "            table_class = fullcredits.findAll('table')\n",
    "            \n",
    "            if len(h4_class)>=3:\n",
    "                k=3\n",
    "            elif len(h4_class) == 0:\n",
    "                k=0\n",
    "            elif len(h4_class) == 1:\n",
    "                k=1\n",
    "            else:\n",
    "                k=2\n",
    "                \n",
    "            for i in range(k):\n",
    "\n",
    "                a = re.match(r'([a-z|A-Z]+)' '?.*', h4_class[i].text.strip())    \n",
    "\n",
    "                if a.groups(1)[0] == 'Directed':\n",
    "                    type4t = 'director'\n",
    "                if a.groups(1)[0] == 'Writing':\n",
    "                    type4t = 'writer'    \n",
    "                if a.groups(1)[0] == 'Cast':\n",
    "                    type4t = 'cast'\n",
    "\n",
    "                tr_class = table_class[i].findAll(\"tr\")           \n",
    "\n",
    "                for td in tr_class:\n",
    "                    for aa in td.findAll('a'):\n",
    "\n",
    "                        # Search name Not character\n",
    "                        if re.search(r'(name)', aa['href']):\n",
    "\n",
    "                            # Write in actor.txt\n",
    "                            if len(aa)!=1:\n",
    "                                f4.write(sno + ';' + type4t + ';' + aa.text.encode('utf-8').strip())\n",
    "                                f4.write('\\n')\n",
    "                            \n",
    "                            # Write in director.txt\n",
    "                            if a.groups(1)[0] == 'Directed':\n",
    "                                f2.write(sno + ';' + type4t + ';' + aa.text.encode('utf-8').strip())\n",
    "                                f2.write('\\n')\n",
    "                            \n",
    "                            # Write in writer.txt\n",
    "                            if a.groups(1)[0] == 'Writing':\n",
    "                                f3.write(sno + ';' + type4t + ';' + aa.text.encode('utf-8').strip())\n",
    "                                f3.write('\\n')\n",
    "                            \n",
    "        except BaseException, e:\n",
    "            print e\n",
    "            print url.strip()\n",
    "            f5.write(url.strip())\n",
    "            f5.write('\\n')            \n",
    "\n",
    "with open('data/IMDB/movies_detail.txt', 'r') as f: \n",
    "    \n",
    "    k=0\n",
    "    for j in f.readlines():\n",
    "        k=k+1\n",
    "        \n",
    "print 'Movies: ' + str(k)\n",
    "print 'Duration: ' + time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - tStart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan Quadrant Vincent 16\n",
      "133\n",
      "Action\n",
      "2015-09-20\n",
      "9.6\n",
      "20\n",
      "1\n",
      "director\n",
      "Rick Sanchez\n"
     ]
    }
   ],
   "source": [
    "### 單一部電影資料測試\n",
    "\n",
    "url = 'http://www.imdb.com/title/tt5044906/'\n",
    "res0 = requests.get(url, verify=True)\n",
    "res0.encoding = 'utf-8'\n",
    "sp0 = BeautifulSoup(res0.text)\n",
    "\n",
    "# IMDB movie title\n",
    "try:\n",
    "    movie_title = sp0.find('div', {'id':'ratingWidget'}).find('strong').text\n",
    "except AttributeError, ae:\n",
    "    movie_title = re.sub(r'(\\(\\))', '', re.sub(r'(\\d)', '', sp0.find('h1', {'itemprop':'name'}).text.strip()))\n",
    "    \n",
    "print movie_title\n",
    "\n",
    "# IMDB movie duration\n",
    "movie_duration = sp0.find('time', {'itemprop':'duration'})['datetime'].replace('PT','').replace('M','')\n",
    "print movie_duration\n",
    "\n",
    "# IMDB movie genre\n",
    "genre = []\n",
    "movie_story = sp0.find('div', {'id':'titleStoryLine'})\n",
    "item = movie_story.find('div', {'itemprop':'genre'})\n",
    "try:\n",
    "    for g in item.findAll('a'):\n",
    "        genre.append(g.text.strip())  \n",
    "except BaseException, e:\n",
    "    genre.append('None') \n",
    "print ','.join(genre)\n",
    "\n",
    "# IMDB movie datePublished\n",
    "movie_date = sp0.find('meta', {'itemprop':'datePublished'})\n",
    "print movie_date['content']\n",
    "\n",
    "# IMDB movie rate value\n",
    "try:\n",
    "    movie_rate_value = sp0.find('span', {'itemprop':'ratingValue'})\n",
    "except BaseException, e:\n",
    "    movie_rate_value = ''\n",
    "print movie_rate_value.text\n",
    "\n",
    "# xxx,xxx IMDb users have given a weighted average vote of 8.5/10\n",
    "try:\n",
    "    movie_rate_count = sp0.find('span', {'itemprop':'ratingCount'})\n",
    "except BaseException,e:\n",
    "    movie_rate_count = ''\n",
    "print movie_rate_count.text\n",
    "\n",
    "# IMDB movie fullcredits\n",
    "# https://github.com/gtb01026/YB101/blob/master/PycharmProjects/BoxOffice/IMDBComplete/release_1970_2010/combine.py\n",
    "movie_fullcredits_url = url + 'fullcredits'\n",
    "res1 = requests.get(movie_fullcredits_url, verify=True)\n",
    "res1.encoding = 'utf-8'\n",
    "sp1 = BeautifulSoup(res1.text)\n",
    "\n",
    "# IMDB movie director/writer\n",
    "#movie_director = sp1.find('div', {'id':'fullcredits_content'})\n",
    "fullcredits = sp1.select(\"#fullcredits_content\")[0]\n",
    "h4_class =  fullcredits.findAll('h4', {'class':'dataHeaderWithBorder'})\n",
    "table_class = fullcredits.findAll('table')\n",
    "print len(h4_class)\n",
    "\n",
    "if len(h4_class)>=3:\n",
    "    k=3\n",
    "elif len(h4_class) == 0:\n",
    "    k=0\n",
    "elif len(h4_class) == 1:\n",
    "    k=1\n",
    "else:\n",
    "    k=2\n",
    "\n",
    "for i in range(k):\n",
    "    #print repr(h4_class[i].text.strip())\n",
    "\n",
    "    credits_list1 = []\n",
    "    a = re.match(r'([a-z|A-Z]+)' '?.*', h4_class[i].text.strip())    \n",
    "\n",
    "    if a.groups(1)[0] == 'Directed':\n",
    "        type4t = 'director'\n",
    "    if a.groups(1)[0] == 'Writing':\n",
    "        type4t = 'writer'    \n",
    "    if a.groups(1)[0] == 'Cast':\n",
    "        type4t = 'cast'\n",
    "\n",
    "    tr_class = table_class[i].findAll(\"tr\")\n",
    "        \n",
    "    #print a.groups(1)[0]  \n",
    "\n",
    "    print type4t\n",
    "\n",
    "    for td in tr_class:\n",
    "        for a in td.findAll('a'):    \n",
    "            if re.search(r'(name)', a['href']):\n",
    "                credits_list1.append(a.text.strip())\n",
    "    print ','.join(credits_list1).replace(',,', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong No.\n"
     ]
    }
   ],
   "source": [
    "with open('data/IMDB/movies_test.txt', 'w') as f: \n",
    "    url = 'http://www.imdb.com/title/tt4635548/'\n",
    "    res0 = requests.get(url, verify=True)\n",
    "    res0.encoding = 'utf-8'\n",
    "    sp0 = BeautifulSoup(res0.text)\n",
    "\n",
    "    # IMDB movie title\n",
    "    movie_title = sp0.find('span', {'class':'itemprop'}).text\n",
    "    print movie_title\n",
    "    f.write(movie_title.encode('utf-8'))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driving While Black \n"
     ]
    }
   ],
   "source": [
    "m = re.sub(r'(\\(\\))', '', re.sub(r'(\\d)', '', 'Driving While Black (2016)'))\n",
    "print m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
